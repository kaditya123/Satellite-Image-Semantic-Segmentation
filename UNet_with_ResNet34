{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":6728837,"sourceType":"datasetVersion","datasetId":3875849}],"dockerImageVersionId":30559,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install patchify","metadata":{"execution":{"iopub.status.busy":"2023-12-06T07:40:36.345022Z","iopub.execute_input":"2023-12-06T07:40:36.345406Z","iopub.status.idle":"2023-12-06T07:40:49.085312Z","shell.execute_reply.started":"2023-12-06T07:40:36.345376Z","shell.execute_reply":"2023-12-06T07:40:49.084167Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport os\nimport cv2\nimport glob\nfrom matplotlib import pyplot as plt\n\nfrom patchify import patchify\nimport tifffile as tiff\nfrom PIL import Image\nimport tensorflow as tf\nfrom tensorflow import keras\n# import segmentation_models as sm\nfrom tensorflow.keras.metrics import MeanIoU\nimport random\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\n# import os\n# for dirname, _, filenames in os.walk('/kaggle/input'):\n#     for filename in filenames:\n#         print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-12-06T07:40:49.087283Z","iopub.execute_input":"2023-12-06T07:40:49.087553Z","iopub.status.idle":"2023-12-06T07:40:58.752264Z","shell.execute_reply.started":"2023-12-06T07:40:49.087529Z","shell.execute_reply":"2023-12-06T07:40:58.751241Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"temp_img = cv2.imread(\"/kaggle/input/potsdam/Potsdam/2_Ortho_RGB/2_Ortho_RGB/top_potsdam_2_10_RGB.tif\") #3 channels / spectral bands\n\n# fig, (ax1, ax2, ax3) = plt.subplots(1, 3)\n# fig.suptitle('Channel wise image of the Red, Green & Infrared spectral band')\n\nplt.imshow(temp_img[:,:,2]) #View each channel...\n# ax2.imshow(temp_img[:,:,1])\n# ax3.imshow(temp_img[:,:,2])\n\ntemp_mask = cv2.imread(\"/kaggle/input/potsdam/Potsdam/5_Labels_all/top_potsdam_2_10_label.tif\") #3 channels but all same.\ntemp_mask_gray = cv2.cvtColor(temp_mask, cv2.COLOR_BGR2GRAY)\n# labels, count = np.unique(temp_mask_gray[:,:,0], return_counts=True) #Check for each channel. All chanels are identical\n\n\nscaling_factor = 5 / 255.0\n\n# Apply the scaling to the image\nscaled_mask = temp_mask_gray * scaling_factor\n\n# Convert to integer values\nscaled_mask = scaled_mask.astype(np.uint8)\n\n\nlabels2, count2 = np.unique(temp_mask_gray, return_counts=True)\nlabels, count = np.unique(scaled_mask, return_counts=True)\nprint(\"Labels are: \", labels, \" and the counts are: \", count)\nprint(\"Labels are: \", labels2, \" and the counts are: \", count2)","metadata":{"execution":{"iopub.status.busy":"2023-12-06T07:40:58.753519Z","iopub.execute_input":"2023-12-06T07:40:58.754249Z","iopub.status.idle":"2023-12-06T07:41:04.876342Z","shell.execute_reply.started":"2023-12-06T07:40:58.754202Z","shell.execute_reply":"2023-12-06T07:41:04.875419Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.imshow(scaled_mask)","metadata":{"execution":{"iopub.status.busy":"2023-12-06T07:41:04.878535Z","iopub.execute_input":"2023-12-06T07:41:04.878849Z","iopub.status.idle":"2023-12-06T07:41:07.216456Z","shell.execute_reply.started":"2023-12-06T07:41:04.878807Z","shell.execute_reply":"2023-12-06T07:41:07.215510Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# import shutil\n# shutil.rmtree(\"/kaggle/working/main_folder/sub_folder\")    ## to delete the directory","metadata":{"execution":{"iopub.status.busy":"2023-12-06T07:41:07.217654Z","iopub.execute_input":"2023-12-06T07:41:07.217969Z","iopub.status.idle":"2023-12-06T07:41:07.221982Z","shell.execute_reply.started":"2023-12-06T07:41:07.217944Z","shell.execute_reply":"2023-12-06T07:41:07.220992Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from pathlib import Path\nPath('/kaggle/working/main_folder/512res_patches').mkdir(parents=True, exist_ok=True)\nPath('/kaggle/working/main_folder/512res_patches/images').mkdir(parents=True, exist_ok=True)\nPath('/kaggle/working/main_folder/512res_patches/masks').mkdir(parents=True, exist_ok=True)\nPath('/kaggle/working/main_folder/data_for_training_and_testing').mkdir(parents=True, exist_ok=True)","metadata":{"execution":{"iopub.status.busy":"2023-12-06T07:41:07.223283Z","iopub.execute_input":"2023-12-06T07:41:07.223626Z","iopub.status.idle":"2023-12-06T07:41:07.232810Z","shell.execute_reply.started":"2023-12-06T07:41:07.223594Z","shell.execute_reply":"2023-12-06T07:41:07.232041Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"root_directory = '/kaggle/input/potsdam/Potsdam'\npatch_size = 384\nimg_dir=\"/kaggle/input/potsdam/Potsdam/2_Ortho_RGB/2_Ortho_RGB\"\nprint(\"1\")","metadata":{"execution":{"iopub.status.busy":"2023-12-06T07:41:07.234010Z","iopub.execute_input":"2023-12-06T07:41:07.234250Z","iopub.status.idle":"2023-12-06T07:41:07.242935Z","shell.execute_reply.started":"2023-12-06T07:41:07.234228Z","shell.execute_reply":"2023-12-06T07:41:07.242079Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for path, subdirs, files in os.walk(img_dir):\n    #print(path)  \n    dirname = path.split(os.path.sep)[-1]\n    #print(dirname)\n    images = os.listdir(path)  #List of all image names in this subdirectory\n    #print(images)\n    for i, image_name in enumerate(images):  \n        if image_name.endswith(\".tif\"):\n            #print(image_name)\n            image = cv2.imread(path+\"/\"+image_name, 1)  #Read each image as BGR\n            SIZE_X = (image.shape[1]//patch_size)*patch_size #Nearest size divisible by our patch size\n            SIZE_Y = (image.shape[0]//patch_size)*patch_size #Nearest size divisible by our patch size\n            image = Image.fromarray(image)\n            image = image.crop((0 ,0, SIZE_X, SIZE_Y))  #Crop from top left corner\n            #image = image.resize((SIZE_X, SIZE_Y))  #Try not to resize for semantic segmentation\n            image = np.array(image)             \n   \n            #Extract patches from each image\n            print(\"Now patchifying image:\", path+\"/\"+image_name)\n            patches_img = patchify(image, (384, 384, 3), step=512)  #Step=512 for 256 patches means no overlap\n            new_name = image_name.replace('_RGB.tif', '')\n            \n            for i in range(patches_img.shape[0]):\n                for j in range(patches_img.shape[1]):\n                    \n                    single_patch_img = patches_img[i,j,:,:]\n                    #single_patch_img = (single_patch_img.astype('float32')) / 255. #We will preprocess using one of the backbones\n                    single_patch_img = single_patch_img[0] #Drop the extra unecessary dimension that patchify adds.                               \n                    \n                    cv2.imwrite(\"/kaggle/working/main_folder/512res_patches/images/\"+\n                               new_name+\"patch_\" + str(i) + str(j) + \".tif\", single_patch_img)\n                    #image_dataset.append(single_patch_img)\n","metadata":{"execution":{"iopub.status.busy":"2023-12-06T07:41:07.244544Z","iopub.execute_input":"2023-12-06T07:41:07.244905Z","iopub.status.idle":"2023-12-06T07:42:42.193841Z","shell.execute_reply.started":"2023-12-06T07:41:07.244874Z","shell.execute_reply":"2023-12-06T07:42:42.192999Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"mask_dir=\"/kaggle/input/potsdam/Potsdam/5_Labels_all\"\nfor path, subdirs, files in os.walk(mask_dir):\n    #print(path)  \n    dirname = path.split(os.path.sep)[-1]\n\n    masks = os.listdir(path)  #List of all image names in this subdirectory\n    for i, mask_name in enumerate(masks):  \n        if mask_name.endswith(\".tif\"):           \n            mask = cv2.imread(path+\"/\"+mask_name, 0)  #Read each image as Grey (or color but remember to map each color to an integer)\n            SIZE_X = (mask.shape[1]//patch_size)*patch_size #Nearest size divisible by our patch size\n            SIZE_Y = (mask.shape[0]//patch_size)*patch_size #Nearest size divisible by our patch size\n            mask = Image.fromarray(mask)\n            mask = mask.crop((0 ,0, SIZE_X, SIZE_Y))  #Crop from top left corner\n            #mask = mask.resize((SIZE_X, SIZE_Y))  #Try not to resize for semantic segmentation\n            mask = np.array(mask)             \n   \n            #Extract patches from each image\n            print(\"Now patchifying mask:\", path+\"/\"+mask_name)\n            patches_mask = patchify(mask, (384, 384), step=512)  #Step=256 for 256 patches means no overlap\n            new_name2 = mask_name.replace('_label.tif', '')\n    \n            for i in range(patches_mask.shape[0]):\n                for j in range(patches_mask.shape[1]):\n                    \n                    single_patch_mask = patches_mask[i,j,:,:]\n                    #single_patch_img = (single_patch_img.astype('float32')) / 255. #No need to scale masks, but you can do it if you want\n                    #single_patch_mask = single_patch_mask[0] #Drop the extra unecessary dimension that patchify adds.                               \n                    cv2.imwrite(\"/kaggle/working/main_folder/512res_patches/masks/\"+\n                               new_name2+\"patch_\"+str(i)+str(j)+\".tif\", single_patch_mask)","metadata":{"execution":{"iopub.status.busy":"2023-12-06T07:42:42.194994Z","iopub.execute_input":"2023-12-06T07:42:42.195284Z","iopub.status.idle":"2023-12-06T07:43:29.960293Z","shell.execute_reply.started":"2023-12-06T07:42:42.195259Z","shell.execute_reply":"2023-12-06T07:43:29.959362Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_img_dir = \"/kaggle/working/main_folder/512res_patches/images/\"\ntrain_mask_dir = \"/kaggle/working/main_folder/512res_patches/masks/\"\nimg_list = os.listdir(train_img_dir)\nmsk_list = os.listdir(train_mask_dir)","metadata":{"execution":{"iopub.status.busy":"2023-12-06T07:43:29.964739Z","iopub.execute_input":"2023-12-06T07:43:29.965046Z","iopub.status.idle":"2023-12-06T07:43:29.976512Z","shell.execute_reply.started":"2023-12-06T07:43:29.965017Z","shell.execute_reply":"2023-12-06T07:43:29.975596Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"len(msk_list), len(img_list)","metadata":{"execution":{"iopub.status.busy":"2023-12-06T07:43:29.977562Z","iopub.execute_input":"2023-12-06T07:43:29.977875Z","iopub.status.idle":"2023-12-06T07:43:29.986092Z","shell.execute_reply.started":"2023-12-06T07:43:29.977827Z","shell.execute_reply":"2023-12-06T07:43:29.985237Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"num_images = len(os.listdir(train_img_dir))\nimg_num = random.randint(0, num_images-1)\n\nimg_for_plot = cv2.imread(train_img_dir+img_list[img_num], 1)\nimg_for_plot = cv2.cvtColor(img_for_plot, cv2.COLOR_BGR2RGB)\n\nmask_for_plot =cv2.imread(train_mask_dir+msk_list[img_num], 0)\n\nplt.figure(figsize=(12, 8))\nplt.subplot(121)\nplt.imshow(img_for_plot)\nplt.title('Image')\nplt.subplot(122)\nplt.imshow(mask_for_plot, cmap='gray')\nplt.title('Mask')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2023-12-06T07:43:29.987135Z","iopub.execute_input":"2023-12-06T07:43:29.987393Z","iopub.status.idle":"2023-12-06T07:43:30.622471Z","shell.execute_reply.started":"2023-12-06T07:43:29.987370Z","shell.execute_reply":"2023-12-06T07:43:30.621561Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from keras.utils import normalize\nfrom keras.metrics import MeanIoU","metadata":{"execution":{"iopub.status.busy":"2023-12-06T07:43:30.623864Z","iopub.execute_input":"2023-12-06T07:43:30.624221Z","iopub.status.idle":"2023-12-06T07:43:30.629036Z","shell.execute_reply.started":"2023-12-06T07:43:30.624192Z","shell.execute_reply":"2023-12-06T07:43:30.628038Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!pip install split-folders","metadata":{"execution":{"iopub.status.busy":"2023-12-06T07:43:30.630278Z","iopub.execute_input":"2023-12-06T07:43:30.630641Z","iopub.status.idle":"2023-12-06T07:43:42.212064Z","shell.execute_reply.started":"2023-12-06T07:43:30.630609Z","shell.execute_reply":"2023-12-06T07:43:42.210899Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import splitfolders\ninput_folder = '/kaggle/working/main_folder/512res_patches'\noutput_folder = '/kaggle/working/main_folder/data_for_training_and_testing'\n# Split with a ratio.\n# To only split into training and validation set, set a tuple to `ratio`, i.e, `(.8, .2)`.\nsplitfolders.ratio(input_folder, output=output_folder, seed=32, ratio=(.6, .4), group_prefix=None) # default values","metadata":{"execution":{"iopub.status.busy":"2023-12-06T07:43:42.213679Z","iopub.execute_input":"2023-12-06T07:43:42.214004Z","iopub.status.idle":"2023-12-06T07:43:44.454740Z","shell.execute_reply.started":"2023-12-06T07:43:42.213975Z","shell.execute_reply":"2023-12-06T07:43:44.453825Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_img_dir = \"/kaggle/working/main_folder/data_for_training_and_testing/train/images/\"\ntrain_mask_dir = \"/kaggle/working/main_folder/data_for_training_and_testing/train/masks/\"\n\nimg_list = os.listdir(train_img_dir)\nmsk_list = os.listdir(train_mask_dir)\n\nnum_images = len(os.listdir(train_img_dir))\nimg_num = random.randint(0, num_images-1)\n\nimg_for_plot = cv2.imread(train_img_dir+img_list[img_num], 1)\nimg_for_plot = cv2.cvtColor(img_for_plot, cv2.COLOR_BGR2RGB)\n\nmask_for_plot =cv2.imread(train_mask_dir+msk_list[img_num], 0)\n\nplt.figure(figsize=(12, 8))\nplt.subplot(121)\nplt.imshow(img_for_plot)\nplt.title('Image')\nplt.subplot(122)\nplt.imshow(mask_for_plot, cmap='gray')\nplt.title('Mask')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2023-12-06T07:43:44.456214Z","iopub.execute_input":"2023-12-06T07:43:44.456574Z","iopub.status.idle":"2023-12-06T07:43:45.101997Z","shell.execute_reply.started":"2023-12-06T07:43:44.456541Z","shell.execute_reply":"2023-12-06T07:43:45.101086Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# !pip install segmentation-models-pytorch","metadata":{"execution":{"iopub.status.busy":"2023-12-06T07:43:45.103190Z","iopub.execute_input":"2023-12-06T07:43:45.103490Z","iopub.status.idle":"2023-12-06T07:43:45.107625Z","shell.execute_reply.started":"2023-12-06T07:43:45.103465Z","shell.execute_reply":"2023-12-06T07:43:45.106826Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import os\nimport cv2\nimport numpy as np\nfrom matplotlib import pyplot as plt\n# import segmentation_models_pytorch as smp\nfrom tensorflow.keras.metrics import MeanIoU\nimport random\nimport tensorflow as tf\nimport keras \n\nfrom keras.utils import normalize\nfrom keras.metrics import MeanIoU\nimport glob\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.utils.data.dataset import Dataset\nimport albumentations as A","metadata":{"execution":{"iopub.status.busy":"2023-12-06T07:43:45.108704Z","iopub.execute_input":"2023-12-06T07:43:45.109376Z","iopub.status.idle":"2023-12-06T07:43:49.917009Z","shell.execute_reply.started":"2023-12-06T07:43:45.109350Z","shell.execute_reply":"2023-12-06T07:43:49.916213Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_img_dir = \"/kaggle/working/main_folder/data_for_training_and_testing/train/images/\"\ntrain_mask_dir = \"/kaggle/working/main_folder/data_for_training_and_testing/train/masks/\"\n\nimg_list = os.listdir(train_img_dir)\nmsk_list = os.listdir(train_mask_dir)\n\nnum_images = len(os.listdir(train_img_dir))\nimg_num = random.randint(0, num_images-1)\n\nimg_for_plot = cv2.imread(train_img_dir+img_list[img_num], 1)\nimg_for_plot = cv2.cvtColor(img_for_plot, cv2.COLOR_BGR2RGB)\n\nmask_for_plot =cv2.imread(train_mask_dir+msk_list[img_num], 0)\n\nplt.figure(figsize=(12, 8))\nplt.subplot(121)\nplt.imshow(img_for_plot)\nplt.title('Image')\nplt.subplot(122)\nplt.imshow(mask_for_plot, cmap='gray')\nplt.title('Mask')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2023-12-06T07:43:49.918267Z","iopub.execute_input":"2023-12-06T07:43:49.918882Z","iopub.status.idle":"2023-12-06T07:43:50.582299Z","shell.execute_reply.started":"2023-12-06T07:43:49.918851Z","shell.execute_reply":"2023-12-06T07:43:50.581399Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!pip install segmentation-models ","metadata":{"execution":{"iopub.status.busy":"2023-12-06T07:43:50.583591Z","iopub.execute_input":"2023-12-06T07:43:50.583948Z","iopub.status.idle":"2023-12-06T07:44:06.655466Z","shell.execute_reply.started":"2023-12-06T07:43:50.583918Z","shell.execute_reply":"2023-12-06T07:44:06.654321Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import glob\nimport cv2\nimport os\nimport numpy as np\nfrom matplotlib import pyplot as plt\n\n!pip install -U -q segmentation-models\nimport os\nos.environ[\"SM_FRAMEWORK\"] = \"tf.keras\"\n\nfrom tensorflow import keras\nimport segmentation_models as sm","metadata":{"execution":{"iopub.status.busy":"2023-12-06T08:22:13.823797Z","iopub.execute_input":"2023-12-06T08:22:13.824168Z","iopub.status.idle":"2023-12-06T08:22:37.105296Z","shell.execute_reply.started":"2023-12-06T08:22:13.824140Z","shell.execute_reply":"2023-12-06T08:22:37.104249Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import keras \n\nfrom keras.utils import normalize\nfrom keras.metrics import MeanIoU","metadata":{"execution":{"iopub.status.busy":"2023-12-06T08:22:37.106906Z","iopub.execute_input":"2023-12-06T08:22:37.107603Z","iopub.status.idle":"2023-12-06T08:22:37.112224Z","shell.execute_reply.started":"2023-12-06T08:22:37.107573Z","shell.execute_reply":"2023-12-06T08:22:37.111136Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"SIZE_X = 384 \nSIZE_Y = 384\nn_classes=6 #Number of classes for segmentation","metadata":{"execution":{"iopub.status.busy":"2023-12-06T08:22:37.113316Z","iopub.execute_input":"2023-12-06T08:22:37.113605Z","iopub.status.idle":"2023-12-06T08:22:37.124126Z","shell.execute_reply.started":"2023-12-06T08:22:37.113580Z","shell.execute_reply":"2023-12-06T08:22:37.123288Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Capture training image info as a list\ntrain_images = []\n\nfor directory_path in glob.glob(\"/kaggle/working/main_folder/data_for_training_and_testing/val/images/\"):\n    for img_path in glob.glob(os.path.join(directory_path, \"*.tif\")):\n        img = cv2.imread(img_path, 1)       \n        #img = cv2.resize(img, (SIZE_Y, SIZE_X))\n#         img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n        train_images.append(img)\n       \n#Convert list to array for machine learning processing        \ntrain_images = np.array(train_images)\n\n#Capture mask/label info as a list\ntrain_masks = [] \nfor directory_path in glob.glob(\"/kaggle/working/main_folder/data_for_training_and_testing/val/masks/\"):\n    for mask_path in glob.glob(os.path.join(directory_path, \"*.tif\")):\n        mask = cv2.imread(mask_path, 0) \n        mask = mask*(5/255)\n        mask = mask.astype(np.uint8)\n        #mask = cv2.resize(mask, (SIZE_Y, SIZE_X), interpolation = cv2.INTER_NEAREST)  #Otherwise ground truth changes due to interpolation\n        train_masks.append(mask)\n        \n#Convert list to array for machine learning processing          \ntrain_masks = np.array(train_masks)","metadata":{"execution":{"iopub.status.busy":"2023-12-06T08:22:54.163672Z","iopub.execute_input":"2023-12-06T08:22:54.164542Z","iopub.status.idle":"2023-12-06T08:23:11.838227Z","shell.execute_reply.started":"2023-12-06T08:22:54.164506Z","shell.execute_reply":"2023-12-06T08:23:11.837291Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_images.shape, train_masks.shape ","metadata":{"execution":{"iopub.status.busy":"2023-12-06T08:23:11.839924Z","iopub.execute_input":"2023-12-06T08:23:11.840259Z","iopub.status.idle":"2023-12-06T08:23:11.848101Z","shell.execute_reply.started":"2023-12-06T08:23:11.840218Z","shell.execute_reply":"2023-12-06T08:23:11.847208Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Encode labels... but multi dim array so need to flatten, encode and reshape\nfrom sklearn.preprocessing import LabelEncoder\nlabelencoder = LabelEncoder()\nn, h, w = train_masks.shape\ntrain_masks_reshaped = train_masks.reshape(-1,1)\ntrain_masks_reshaped_encoded = labelencoder.fit_transform(train_masks_reshaped)\ntrain_masks_encoded_original_shape = train_masks_reshaped_encoded.reshape(n, h, w)\n\nnp.unique(train_masks_encoded_original_shape)\n","metadata":{"execution":{"iopub.status.busy":"2023-12-06T08:23:11.849190Z","iopub.execute_input":"2023-12-06T08:23:11.849444Z","iopub.status.idle":"2023-12-06T08:23:30.724691Z","shell.execute_reply.started":"2023-12-06T08:23:11.849422Z","shell.execute_reply":"2023-12-06T08:23:30.723703Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_masks_input = np.expand_dims(train_masks_encoded_original_shape, axis=3)\n\n#Create a subset of data for quick testing\n#Picking 10% for testing and remaining for training\nfrom sklearn.model_selection import train_test_split\nX1, X_test, y1, y_test = train_test_split(train_images, train_masks_input, test_size = 0.10, random_state = 0)\n\n#Further split training data t a smaller subset for quick testing of models\nX_train, X_do_not_use, y_train, y_do_not_use = train_test_split(X1, y1, test_size = 0.1, random_state = 0)\n\nprint(\"Class values in the dataset are ... \", np.unique(y_train))  # 0 is the background/few unlabeled \n","metadata":{"execution":{"iopub.status.busy":"2023-12-06T08:23:30.727917Z","iopub.execute_input":"2023-12-06T08:23:30.728337Z","iopub.status.idle":"2023-12-06T08:23:37.613739Z","shell.execute_reply.started":"2023-12-06T08:23:30.728308Z","shell.execute_reply":"2023-12-06T08:23:37.612769Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from keras.utils import to_categorical\ntrain_masks_cat = to_categorical(y_train, num_classes=n_classes)\ny_train_cat = train_masks_cat.reshape((y_train.shape[0], y_train.shape[1], y_train.shape[2], n_classes))\n\n\n\ntest_masks_cat = to_categorical(y_test, num_classes=n_classes)\ny_test_cat = test_masks_cat.reshape((y_test.shape[0], y_test.shape[1], y_test.shape[2], n_classes))","metadata":{"execution":{"iopub.status.busy":"2023-12-06T08:23:37.614789Z","iopub.execute_input":"2023-12-06T08:23:37.615101Z","iopub.status.idle":"2023-12-06T08:23:44.319940Z","shell.execute_reply.started":"2023-12-06T08:23:37.615074Z","shell.execute_reply":"2023-12-06T08:23:44.318891Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_train.shape, y_train_cat.shape","metadata":{"execution":{"iopub.status.busy":"2023-12-06T08:23:44.321142Z","iopub.execute_input":"2023-12-06T08:23:44.321460Z","iopub.status.idle":"2023-12-06T08:23:44.327751Z","shell.execute_reply.started":"2023-12-06T08:23:44.321434Z","shell.execute_reply":"2023-12-06T08:23:44.326842Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"n_classes=6\nactivation='softmax'\n\nLR = 0.0001\noptim = keras.optimizers.Adam(LR)\n\n# Segmentation models losses can be combined together by '+' and scaled by integer or float factor\n# set class weights for dice_loss (car: 1.; pedestrian: 2.; background: 0.5;)\ndice_loss = sm.losses.DiceLoss(class_weights=np.array([0.65528844, 3.56154108, 1.07120728, 0.73141398, 6.44243807,\n       0.57563383])) \nfocal_loss = sm.losses.CategoricalFocalLoss()\ntotal_loss = dice_loss + (1 * focal_loss)\n\n# actulally total_loss can be imported directly from library, above example just show you how to manipulate with losses\n# total_loss = sm.losses.binary_focal_dice_loss # or sm.losses.categorical_focal_dice_loss \n\nmetrics = [sm.metrics.IOUScore(threshold=0.5), sm.metrics.FScore(threshold=0.5)]","metadata":{"execution":{"iopub.status.busy":"2023-12-06T08:23:44.329099Z","iopub.execute_input":"2023-12-06T08:23:44.329820Z","iopub.status.idle":"2023-12-06T08:23:44.348387Z","shell.execute_reply.started":"2023-12-06T08:23:44.329784Z","shell.execute_reply":"2023-12-06T08:23:44.347401Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"BACKBONE1 = 'resnet50'\npreprocess_input1 = sm.get_preprocessing(BACKBONE1)\n\n# preprocess input\nX_train1 = preprocess_input1(X_train)\nX_test1 = preprocess_input1(X_test)","metadata":{"execution":{"iopub.status.busy":"2023-12-06T08:23:44.349595Z","iopub.execute_input":"2023-12-06T08:23:44.349907Z","iopub.status.idle":"2023-12-06T08:23:44.355104Z","shell.execute_reply.started":"2023-12-06T08:23:44.349876Z","shell.execute_reply":"2023-12-06T08:23:44.354308Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# define model\nmodel1 = sm.Unet(BACKBONE1, encoder_weights='imagenet', classes=n_classes, activation=activation)\n\n# compile keras model with defined optimozer, loss and metrics\nmodel1.compile(optim, total_loss, metrics=metrics)","metadata":{"execution":{"iopub.status.busy":"2023-12-06T08:23:44.356265Z","iopub.execute_input":"2023-12-06T08:23:44.356537Z","iopub.status.idle":"2023-12-06T08:23:51.154382Z","shell.execute_reply.started":"2023-12-06T08:23:44.356514Z","shell.execute_reply":"2023-12-06T08:23:51.153477Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# print(model1.summary())","metadata":{"execution":{"iopub.status.busy":"2023-12-06T07:45:13.225091Z","iopub.execute_input":"2023-12-06T07:45:13.225373Z","iopub.status.idle":"2023-12-06T07:45:13.229526Z","shell.execute_reply.started":"2023-12-06T07:45:13.225348Z","shell.execute_reply":"2023-12-06T07:45:13.228601Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"history1=model1.fit(X_train1, \n          y_train_cat,\n          batch_size=8, \n          epochs=20,\n          verbose=1,\n          validation_data=(X_test1, y_test_cat))\n","metadata":{"execution":{"iopub.status.busy":"2023-12-06T07:45:13.230519Z","iopub.execute_input":"2023-12-06T07:45:13.230762Z","iopub.status.idle":"2023-12-06T08:15:18.705465Z","shell.execute_reply.started":"2023-12-06T07:45:13.230740Z","shell.execute_reply":"2023-12-06T08:15:18.704455Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model1.save('UNet_res50_backbone_20epochs.hdf5')","metadata":{"execution":{"iopub.status.busy":"2023-12-06T08:23:51.157057Z","iopub.execute_input":"2023-12-06T08:23:51.157502Z","iopub.status.idle":"2023-12-06T08:23:51.819203Z","shell.execute_reply.started":"2023-12-06T08:23:51.157473Z","shell.execute_reply":"2023-12-06T08:23:51.818336Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model = model1.compile(optim, total_loss, metrics=metrics)\n# Evaluate the model on the test set\nevaluation = model1.evaluate(x=X_test1, y= y_test_cat, batch_size=8)\n\n# Extract the accuracy from the evaluation\naccuracy = evaluation[1] * 100  # Assuming accuracy is the second metric\n\n# Print the accuracy\nprint(f\"Test set accuracy: {accuracy:.2f}%\")","metadata":{"execution":{"iopub.status.busy":"2023-12-06T08:26:36.155074Z","iopub.execute_input":"2023-12-06T08:26:36.155496Z","iopub.status.idle":"2023-12-06T08:26:42.375253Z","shell.execute_reply.started":"2023-12-06T08:26:36.155467Z","shell.execute_reply":"2023-12-06T08:26:42.374346Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"loss = history1.history['loss']\nval_loss = history1.history['val_loss']\nepochs = range(1, len(loss) + 1)\nplt.plot(epochs, loss, 'y', label='Training loss')\nplt.plot(epochs, val_loss, 'r', label='Validation loss')\nplt.title('Training and validation loss')\nplt.xlabel('Epochs')\nplt.ylabel('Loss')\nplt.legend()\nplt.show()\n\nacc = history1.history['iou_score']\nval_acc = history1.history['val_iou_score']\n\nplt.plot(epochs, acc, 'y', label='Training IOU')\nplt.plot(epochs, val_acc, 'r', label='Validation IOU')\nplt.title('Training and validation IOU')\nplt.xlabel('Epochs')\nplt.ylabel('IOU')\nplt.legend()\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2023-12-06T08:26:45.278728Z","iopub.execute_input":"2023-12-06T08:26:45.279094Z","iopub.status.idle":"2023-12-06T08:26:45.342235Z","shell.execute_reply.started":"2023-12-06T08:26:45.279067Z","shell.execute_reply":"2023-12-06T08:26:45.341063Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from keras.models import load_model\nmodel1 = load_model('UNet_res50_backbone_20epochs.hdf5', compile=False)\n#IOU\ny_pred1=model1.predict(X_test1)\ny_pred1_argmax=np.argmax(y_pred1, axis=3)","metadata":{"execution":{"iopub.status.busy":"2023-12-06T08:26:47.993886Z","iopub.execute_input":"2023-12-06T08:26:47.994236Z","iopub.status.idle":"2023-12-06T08:27:14.730205Z","shell.execute_reply.started":"2023-12-06T08:26:47.994211Z","shell.execute_reply":"2023-12-06T08:27:14.729067Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Using built in keras function\n#from keras.metrics import MeanIoU\nn_classes = 6\nIOU_keras = MeanIoU(num_classes=n_classes)  \nIOU_keras.update_state(y_test[:,:,:,0], y_pred1_argmax)\nprint(\"Mean IoU =\", IOU_keras.result().numpy())","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#To calculate I0U for each class...\nvalues = np.array(IOU_keras.get_weights()).reshape(n_classes, n_classes)\nprint(values)\nclass1_IoU = values[0,0]/(values[0,0] + values[0,1] + values[0,2] + values[0,3] + values[1,0]+ values[2,0]+ values[3,0])\nclass2_IoU = values[1,1]/(values[1,1] + values[1,0] + values[1,2] + values[1,3] + values[0,1]+ values[2,1]+ values[3,1])\nclass3_IoU = values[2,2]/(values[2,2] + values[2,0] + values[2,1] + values[2,3] + values[0,2]+ values[1,2]+ values[3,2])\nclass4_IoU = values[3,3]/(values[3,3] + values[3,0] + values[3,1] + values[3,2] + values[0,3]+ values[1,3]+ values[2,3])\nclass5_IoU = values[4,4]/(values[4,4] + values[4,0] + values[4,1] + values[4,2] + values[0,4]+ values[1,4]+ values[2,4])\nclass6_IoU = values[5,5]/(values[5,5] + values[5,0] + values[5,1] + values[5,2] + values[0,5]+ values[1,5]+ values[2,5])\n\nprint(\"IoU for class1: Building is: \", class1_IoU)\nprint(\"IoU for class2: Impervious Surface is: \", class2_IoU)\nprint(\"IoU for class3: Trees is: \", class3_IoU)\nprint(\"IoU for class4: Low Vegetation is: \", class4_IoU)\nprint(\"IoU for class5: Car is: \", class5_IoU)\nprint(\"IoU for class6: Clutter/Background is: \", class6_IoU)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import random\ntest_img_number = random.randint(0, len(X_test1))\ntest_img = X_test1[test_img_number]\nground_truth=y_test[test_img_number]\ntest_img_input=np.expand_dims(test_img, 0)\n\ntest_img_input1 = preprocess_input1(test_img_input)\n\ntest_pred1 = model1.predict(test_img_input1)\ntest_prediction1 = np.argmax(test_pred1, axis=3)[0,:,:]\n\n\nplt.figure(figsize=(12, 8))\nplt.subplot(231)\nplt.title('Testing Image')\nplt.imshow(test_img[:,:,0], cmap='gray')\nplt.subplot(232)\nplt.title('Testing Label')\nplt.imshow(ground_truth[:,:,0], cmap='jet')\nplt.subplot(233)\nplt.title('Prediction on test image')\nplt.imshow(test_prediction1, cmap='jet')\nplt.show()\nprint(test_img_number)","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}